{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training. Data has alreday been setup - test_sentiment140.csv_noquotes.csv & training_sentiment140_noquotes.csv\n",
    "\n",
    "Exmplanation of Hyperparameters here: https://docs.aws.amazon.com/sagemaker/latest/dg/blazingtext_hyperparameters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::459367279383:role/service-role/AmazonSageMaker-ExecutionRole-20190801T095874\n",
      "venkat1-ml-sagemaker\n"
     ]
    }
   ],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role) # This is the role that SageMaker would use to leverage AWS resources (S3, CloudWatch) on your behalf\n",
    "\n",
    "bucket = 'venkat1-ml-sagemaker' #sess.default_bucket() # Replace with your own bucket name if needed\n",
    "print(bucket)\n",
    "prefix = 'Sentiment140/supervised' #Replace with the prefix under which you want to store the data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.28 s, sys: 408 ms, total: 1.68 s\n",
      "Wall time: 8.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "\n",
    "sess.upload_data(path='training_sentiment140_noquotes.csv', bucket=bucket, key_prefix=train_channel)\n",
    "sess.upload_data(path='test_sentiment140.csv_noquotes.csv', bucket=bucket, key_prefix=validation_channel)\n",
    "\n",
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SageMaker BlazingText container: 811284229777.dkr.ecr.us-east-1.amazonaws.com/blazingtext:latest (us-east-1)\n"
     ]
    }
   ],
   "source": [
    "region_name = boto3.Session().region_name\n",
    "\n",
    "container = sagemaker.amazon.amazon_estimator.get_image_uri(region_name, \"blazingtext\", \"latest\")\n",
    "print('Using SageMaker BlazingText container: {} ({})'.format(container, region_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is where we Run the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.c4.4xlarge',\n",
    "                                         train_volume_size = 30,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_model.set_hyperparameters(mode=\"supervised\",\n",
    "                            epochs=10,\n",
    "                            min_count=2,\n",
    "                            learning_rate=0.05,\n",
    "                            vector_dim=10,\n",
    "                            early_stopping=True,\n",
    "                            patience=4,\n",
    "                            min_epochs=5,\n",
    "                            word_ngrams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_data, distribution='FullyReplicated', \n",
    "                        content_type='text/plain', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "                             content_type='text/plain', s3_data_type='S3Prefix')\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-21 18:49:47 Starting - Starting the training job...\n",
      "2019-10-21 18:49:57 Starting - Launching requested ML instances......\n",
      "2019-10-21 18:51:01 Starting - Preparing the instances for training......\n",
      "2019-10-21 18:52:10 Downloading - Downloading input data\n",
      "2019-10-21 18:52:10 Training - Downloading the training image..\u001b[31mArguments: train\u001b[0m\n",
      "\u001b[31m[10/21/2019 18:52:24 WARNING 139996456646464] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[10/21/2019 18:52:24 WARNING 139996456646464] Loggers have already been setup.\u001b[0m\n",
      "\u001b[31m[10/21/2019 18:52:24 INFO 139996456646464] nvidia-smi took: 0.0252268314362 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[31m[10/21/2019 18:52:24 INFO 139996456646464] Running single machine CPU BlazingText training using supervised mode.\u001b[0m\n",
      "\u001b[31m[10/21/2019 18:52:24 INFO 139996456646464] Processing /opt/ml/input/data/train/training_sentiment140_noquotes.csv . File size: 93 MB\u001b[0m\n",
      "\u001b[31m[10/21/2019 18:52:24 INFO 139996456646464] Processing /opt/ml/input/data/validation/test_sentiment140.csv_noquotes.csv . File size: 40 MB\u001b[0m\n",
      "\u001b[31mRead 10M words\u001b[0m\n",
      "\u001b[31mRead 16M words\u001b[0m\n",
      "\u001b[31mNumber of words:  178971\u001b[0m\n",
      "\u001b[31mLoading validation data from /opt/ml/input/data/validation/test_sentiment140.csv_noquotes.csv\u001b[0m\n",
      "\u001b[31mLoaded validation data.\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 5\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.800094\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0225  Progress: 55.05%  Million Words/sec: 28.40 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0197  Progress: 60.62%  Million Words/sec: 28.57 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 6\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.801673\u001b[0m\n",
      "\u001b[31mValidation accuracy improved! Storing best weights...\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0166  Progress: 66.78%  Million Words/sec: 27.22 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 7\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.800312\u001b[0m\n",
      "\u001b[31mValidation accuracy has not improved for last 1 epochs.\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0138  Progress: 72.37%  Million Words/sec: 26.37 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0109  Progress: 78.25%  Million Words/sec: 26.73 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 8\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.799571\u001b[0m\n",
      "\u001b[31mValidation accuracy has not improved for last 2 epochs.\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0082  Progress: 83.68%  Million Words/sec: 25.99 #####\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0052  Progress: 89.60%  Million Words/sec: 26.34 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 9\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.798188\u001b[0m\n",
      "\u001b[31mValidation accuracy has not improved for last 3 epochs.\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0022  Progress: 95.50%  Million Words/sec: 25.85 #####\u001b[0m\n",
      "\u001b[31m-------------- End of epoch: 10\u001b[0m\n",
      "\u001b[31mUsing 16 threads for prediction!\u001b[0m\n",
      "\u001b[31mValidation accuracy: 0.798727\u001b[0m\n",
      "\u001b[31mValidation accuracy has not improved for last 4 epochs.\u001b[0m\n",
      "\u001b[31mReached patience. Terminating training.\u001b[0m\n",
      "\u001b[31mBest epoch: 6\u001b[0m\n",
      "\u001b[31mBest validation accuracy: 0.801673\u001b[0m\n",
      "\u001b[31m##### Alpha: 0.0000  Progress: 100.00%  Million Words/sec: 25.49 #####\u001b[0m\n",
      "\n",
      "2019-10-21 18:52:40 Uploading - Uploading generated training model\u001b[31mTraining finished.\u001b[0m\n",
      "\u001b[31mAverage throughput in Million words/sec: 25.49\u001b[0m\n",
      "\u001b[31mTotal training time in seconds: 6.45\n",
      "\u001b[0m\n",
      "\u001b[31m#train_accuracy: 0.9166\u001b[0m\n",
      "\u001b[31mNumber of train examples: 1120000\n",
      "\u001b[0m\n",
      "\u001b[31m#validation_accuracy: 0.8017\u001b[0m\n",
      "\u001b[31mNumber of validation examples: 480000\u001b[0m\n",
      "\n",
      "2019-10-21 18:52:56 Completed - Training job completed\n",
      "Training seconds: 63\n",
      "Billable seconds: 63\n"
     ]
    }
   ],
   "source": [
    "bt_model.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "text_classifier = bt_model.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9779990315437317,\n",
      "      0.022020963951945305\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Positive\",\n",
      "      \"__label__Negative\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9650333523750305,\n",
      "      0.034986693412065506\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Positive\",\n",
      "      \"__label__Negative\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.8431633710861206,\n",
      "      0.15685658156871796\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Negative\",\n",
      "      \"__label__Positive\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.8228063583374023,\n",
      "      0.17721359431743622\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Negative\",\n",
      "      \"__label__Positive\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.6642078757286072,\n",
      "      0.33581212162971497\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Negative\",\n",
      "      \"__label__Positive\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"prob\": [\n",
      "      0.9880969524383545,\n",
      "      0.01192310731858015\n",
      "    ],\n",
      "    \"label\": [\n",
      "      \"__label__Positive\",\n",
      "      \"__label__Negative\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentences = [\"Hey, Connor. Money in Hand is good, money in head is bad\",\n",
    "            \"what was he thinking?\", \n",
    "             \"morning all... looks like its gonna be a rainy day \",\n",
    "            \"hard to be witty when one is at their wits end\",\n",
    "            \"Crazy day tomorow. Meetings all day\",\n",
    "            \"looking forward to the weekend\"]\n",
    "\n",
    "# using the same nltk tokenizer that we used during data preparation for training\n",
    "tokenized_sentences = [' '.join(nltk.word_tokenize(sent)) for sent in sentences]\n",
    "\n",
    "payload = {\"instances\" : tokenized_sentences,\n",
    "          \"configuration\": {\"k\": 2}}\n",
    "\n",
    "response = text_classifier.predict(json.dumps(payload))\n",
    "\n",
    "predictions = json.loads(response)\n",
    "print(json.dumps(predictions, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(text_classifier.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
